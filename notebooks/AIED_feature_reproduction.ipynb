{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T15:19:34.253244Z",
     "start_time": "2020-11-10T15:19:31.487694Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "from datetime import datetime, timedelta, date\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T15:19:38.389133Z",
     "start_time": "2020-11-10T15:19:34.257010Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from helpers.db_query import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly video count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T15:19:39.149050Z",
     "start_time": "2020-11-10T15:19:38.395195Z"
    }
   },
   "outputs": [],
   "source": [
    "video_dates = pd.read_csv('../data/lin_alg_moodle/videos.csv', index_col=0)\n",
    "video_dates['Due_date'] = pd.to_datetime(video_dates.Due_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T15:19:39.465121Z",
     "start_time": "2020-11-10T15:19:39.152691Z"
    }
   },
   "outputs": [],
   "source": [
    "def select_by_year(video_dates, year):\n",
    "    return video_dates.loc[video_dates.Due_date.dt.year == year]\n",
    "\n",
    "video_dates_2017, video_dates_2018, video_dates_2019 = [select_by_year(video_dates, year) for year in [2017,2018, 2019]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T15:19:39.536343Z",
     "start_time": "2020-11-10T15:19:39.467538Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 [ 6  9  6 12  7]\n",
      "2018 [ 7 10 10  6 13  7  8  7  9  6]\n",
      "2019 [ 5  4  8  7  7 10 11 13  7  8  6  9  6]\n"
     ]
    }
   ],
   "source": [
    "def weekly_count(video_dates):\n",
    "    return video_dates.groupby(pd.Grouper(key='Due_date',freq='W-THU')).size().values\n",
    "\n",
    "count_2017, count_2018, count_2019 = [weekly_count(dates) for dates in [video_dates_2017, video_dates_2018,video_dates_2019]]\n",
    "print(\"2017\", count_2017)\n",
    "print(\"2018\", count_2018)\n",
    "print(\"2019\", count_2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "## Video views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T15:21:28.951639Z",
     "start_time": "2020-11-10T15:19:39.543581Z"
    }
   },
   "outputs": [],
   "source": [
    "events = getVideoEvents(mode='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T18:04:44.132256Z",
     "start_time": "2020-11-10T18:04:44.044820Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataPackageID</th>\n",
       "      <th>AccountUserID</th>\n",
       "      <th>VideoID</th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>EventType</th>\n",
       "      <th>SeekType</th>\n",
       "      <th>OldTime</th>\n",
       "      <th>CurrentTime</th>\n",
       "      <th>NewTime</th>\n",
       "      <th>OldSpeed</th>\n",
       "      <th>NewSpeed</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>782231</th>\n",
       "      <td>EPFL-AlgebreLineaire-2018</td>\n",
       "      <td>47670</td>\n",
       "      <td>b3b3943d538b4282b1608fbe3a8619d8</td>\n",
       "      <td>1542143265</td>\n",
       "      <td>Video.Pause</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.8866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-11-13 21:07:45</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DataPackageID AccountUserID  \\\n",
       "782231  EPFL-AlgebreLineaire-2018         47670   \n",
       "\n",
       "                                 VideoID   TimeStamp    EventType SeekType  \\\n",
       "782231  b3b3943d538b4282b1608fbe3a8619d8  1542143265  Video.Pause     None   \n",
       "\n",
       "        OldTime  CurrentTime  NewTime  OldSpeed  NewSpeed                Date  \\\n",
       "782231      NaN      36.8866      NaN       NaN       NaN 2018-11-13 21:07:45   \n",
       "\n",
       "        Year  \n",
       "782231  2018  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T19:53:01.555506Z",
     "start_time": "2020-11-10T19:53:01.349162Z"
    }
   },
   "outputs": [],
   "source": [
    "user_events = events.loc[events.AccountUserID == '47670']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T15:33:46.966686Z",
     "start_time": "2020-11-10T15:33:46.914406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of videos watched 100\n"
     ]
    }
   ],
   "source": [
    "def total_views(df):\n",
    "    \"\"\" \n",
    "    Counts the total of videos views (rewatch included)\n",
    "    Assumption: consider that a video is watched at most once per day\n",
    "    \"\"\"\n",
    "    copy = df.copy()\n",
    "    copy['Day'] = df.Date.dt.date\n",
    "    #From the assumption the video view is a unique pair (video id, day)\n",
    "    return len(copy.drop_duplicates(subset=['VideoID','Day'])) \n",
    "print(\"Total number of videos watched\",total_views(user_events))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Weekly proportion (watched/replayed/interrupted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T17:59:22.362466Z",
     "start_time": "2020-11-10T17:59:18.356863Z"
    }
   },
   "outputs": [],
   "source": [
    "def week_video_total(year):\n",
    "    \"\"\"\n",
    "    Returns a Series with week numbers as index and the number of videos to watch per week\n",
    "    \"\"\"\n",
    "    with open('../config/linear_algebra.json') as f:\n",
    "        config = json.load(f)\n",
    "    year = str(year)\n",
    "    weekly_count = config[year][\"WeeklyVideoCount\"]\n",
    "    flipped_weeks = len(config[year][\"FlippedWeeks\"])\n",
    "    start_week = int(datetime.strptime(config[year][\"StartFlipped\"], '%Y-%m-%d').strftime(\"%V\")) #Get the 1st week number\n",
    "    weeks = list(range(start_week, start_week + flipped_weeks))\n",
    "    return pd.DataFrame(index=weeks, data=weekly_count, columns=[\"Total\"])\n",
    "\n",
    "def get_dated_videos():\n",
    "    PATH = '../data/lin_alg_moodle/video_with_durations.csv'\n",
    "    dated_videos = pd.read_csv(PATH, index_col=0)\n",
    "    dated_videos['Due_date'] = pd.to_datetime(dated_videos['Due_date']) #Convert String to datetime\n",
    "    dated_videos['Year'] = dated_videos.Due_date.dt.year #Add year column\n",
    "    return dated_videos\n",
    "\n",
    "def videos_watched_on_right_week(user_events):\n",
    "    dated_videos = get_dated_videos()\n",
    "    first_views = user_events.merge(dated_videos, on=['VideoID', 'Year'])\n",
    "    first_views['From_date'] = first_views.Due_date - timedelta(weeks=1)\n",
    "    return first_views[(first_views.Date >= first_views.From_date) & (first_views.Date <= first_views.Due_date)]\n",
    "\n",
    "def weekly_prop(user_events):\n",
    "    \"\"\"Compute the ratio of video events in the dataframe over the videos assigned weekly the user_events\n",
    "    may only contained only the first viewings, only rewatched videos or only interrupted videos.\"\"\"\n",
    "    first_views = videos_watched_on_right_week(user_events)\n",
    "    #Freq Weekly starting on Thursday since the last due date is on Thursday\n",
    "    weekly_count = first_views.groupby(pd.Grouper(key=\"Date\", freq=\"W-THU\")).size().to_frame(name=\"Count\")\n",
    "    #Convert dates to week number\n",
    "    weekly_count.index = [int(week) for week in weekly_count.index.strftime(\"%V\")]\n",
    "    #Number of assigned videos per week\n",
    "    weekly_total = week_video_total(user_events.Year.iloc[0])\n",
    "    #Merge and compute the ratio of watched\n",
    "    weekly_prop = weekly_total.merge(weekly_count, left_index=True, right_index=True)\n",
    "    return np.clip((weekly_prop.Count / weekly_prop.Total).values,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T15:33:49.650401Z",
     "start_time": "2020-11-10T15:33:47.599994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos watched\n",
      "Average 0.5223901098901099\n",
      "SG 0.2542535527448914\n"
     ]
    }
   ],
   "source": [
    "# Average and SD of the proportion of videos watched per week\n",
    "def weekly_prop_watched(user_events):\n",
    "    \"\"\"Compute the proportion of videos watched (nb of videos watched / nb of videos assigned)\"\"\"\n",
    "    first_views = user_events.drop_duplicates(subset=[\"VideoID\"]) #Only keep the first views per video\n",
    "    return weekly_prop(first_views)\n",
    "\n",
    "def avg_weekly_prop_watched(df): \n",
    "    return weekly_prop_watched(df).mean()\n",
    "\n",
    "def std_weekly_prop_watched(df):\n",
    "    return weekly_prop_watched(df).std()\n",
    "\n",
    "print(\"Videos watched\")\n",
    "print(\"Average\",avg_weekly_prop_watched(user_events))\n",
    "print(\"SG\",std_weekly_prop_watched(user_events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T15:33:50.999089Z",
     "start_time": "2020-11-10T15:33:49.654783Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos replayed\n",
      "Average 0.08535714285714285\n",
      "SG 0.13283073854360974\n"
     ]
    }
   ],
   "source": [
    "# Average and SD of the proportion of videos replayed per week\n",
    "def weekly_prop_replayed(user_events):\n",
    "    \"\"\"Compute the proportion of videos replayed (nb of videos replayed / nb of videos assigned)\"\"\"\n",
    "    # We assume that a student watches a video at most once per day (cannot have multiple replays in one day)\n",
    "    replayed_events = user_events.copy()\n",
    "    replayed_events['Day'] = replayed_events.Date.dt.date #Create column with the date but not the time\n",
    "    replayed_events.drop_duplicates(subset=['VideoID', 'Day'], inplace=True) #Only keep on event per video per day\n",
    "    replayed_events = replayed_events[replayed_events.duplicated(subset=['VideoID'])] # Keep the replayed videos\n",
    "    return weekly_prop(replayed_events)\n",
    "\n",
    "def avg_weekly_prop_replayed(df): \n",
    "    return weekly_prop_replayed(df).mean()\n",
    "\n",
    "def std_weekly_prop_replayed(df):\n",
    "    return weekly_prop_replayed(df).std()\n",
    "\n",
    "print(\"Videos replayed\")\n",
    "print(\"Average\",avg_weekly_prop_replayed(user_events))\n",
    "print(\"SG\",std_weekly_prop_replayed(user_events))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interruption exploration\n",
    "\n",
    "There is no interruption event. In fact there exists an event called `Video.Stop` but it consists of the union of event types causing an interruption of the video, for instance `Video.Pause` or `Video.Load`. However I noticed that some events occurred at the same time as the end of the video: **is there a \"closing event\" that always occur at the end of the video?**\n",
    "\n",
    "In order to test that, the `interruption` function returns the video events occurring in the `time_threshold` last seconds. By computing the proportion of videos where an event occurred in the last seconds and the total number of unique videos watched, we can have a approximative idea of how often an \"interruption event\" occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T18:36:50.935135Z",
     "start_time": "2020-11-10T18:36:49.574943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos containing an closing event: 70\n",
      "Total number of distinct videos watched: 85\n"
     ]
    }
   ],
   "source": [
    "def interruption(df, time_threshold=60):\n",
    "    \"\"\"Returns events occurring in the last time_threshold seconds (max one event per video) \"\"\"\n",
    "    user_event['Day'] = user_event.Date.dt.date #Create column with the date but not the time\n",
    "    dated_videos = get_dated_videos()\n",
    "    user_event = user_event.merge(dated_videos, on=['VideoID', 'Year'])\n",
    "    return user_event[abs(user_event.CurrentTime - user_event.Duration) < time_threshold]\\\n",
    "                                                                    .drop_duplicates(subset=['VideoID'])\n",
    "\n",
    "print(\"Number of videos containing an closing event:\",len(interruption(user_events)))\n",
    "print(\"Total number of distinct videos watched:\", len(user_events.drop_duplicates(subset=['VideoID'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T18:29:21.179998Z",
     "start_time": "2020-11-10T18:26:02.582280Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 407/407 [03:18<00:00,  2.05it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def compute_closing_prop():\n",
    "    \"\"\"Compute the proportion of videos containing an closing event for each user\"\"\"\n",
    "    till_end_prop = []\n",
    "    for userId in tqdm(events.AccountUserID.unique()):\n",
    "        user_events = events.loc[events.AccountUserID == userId]\n",
    "        total = len(user_events.drop_duplicates(subset=['VideoID']))\n",
    "        if total != 0:\n",
    "            till_end_prop.append(len(interruption(user_events)) / total)\n",
    "    return np.array(till_end_prop)\n",
    "\n",
    "till_end_prop = compute_closing_prop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T18:29:21.626537Z",
     "start_time": "2020-11-10T18:29:21.186828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average proportion of videos with closing event: 0.5847724703777055\n",
      "SD of the proportion of videos with closing event: 0.24759822134344328\n"
     ]
    }
   ],
   "source": [
    "print(\"Average proportion of videos with closing event:\",till_end_prop.mean())\n",
    "print(\"SD of the proportion of videos with closing event:\",till_end_prop.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in average 60% ($\\pm$ 25%) of the videos end with an event occurring in the last minute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T18:46:39.931983Z",
     "start_time": "2020-11-10T18:46:39.457558Z"
    }
   },
   "outputs": [],
   "source": [
    "ACTIONS = ['Video.Play', 'Video.Pause', 'Video.SeekBackward', 'Video.SeekForward', 'Video.SpeedChange', 'Video.Stop']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T19:04:36.975169Z",
     "start_time": "2020-11-10T19:04:36.693190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of actions: 2739\n"
     ]
    }
   ],
   "source": [
    "def total_actions(user_events):\n",
    "    \"\"\"Counts the total number of actions performed across every videos\"\"\"\n",
    "    return len(user_events)\n",
    "\n",
    "print(\"Total number of actions:\", total_actions(user_events))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of all actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T19:15:04.766138Z",
     "start_time": "2020-11-10T19:15:04.294824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.72589533563976 actions / hour\n"
     ]
    }
   ],
   "source": [
    "def frequency_all_actions(user_events):\n",
    "    \"\"\"Compute the frequency of actions performed per hour spent watching videos\"\"\"\n",
    "    user_events = user_events.copy()\n",
    "    user_events.loc[:,'Day'] = user_events.loc[:,'Date'].dt.date #Create column with the date but not the time\n",
    "    user_events.drop_duplicates(subset=['VideoID', 'Day'], inplace=True) #Only keep on event per video per day\n",
    "    durations = get_dated_videos()\n",
    "    user_events = user_events.merge(durations, on = [\"VideoID\", \"Year\"])\n",
    "    watching_time = user_events.Duration.sum() / 3600 # hours\n",
    "    return total_actions(user_events) / watching_time if watching_time != 0 else 0\n",
    "\n",
    "print(frequency_all_actions(user_events),\"actions / hour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of each action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T19:35:50.045479Z",
     "start_time": "2020-11-10T19:35:49.986701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play 0.41509433962264153\n",
      "pause 0.27358490566037735\n",
      "seek_backward 0.009433962264150943\n",
      "seek_forward 0.018867924528301886\n",
      "speed_change 0.0\n",
      "stop 0.05660377358490566\n",
      "Total proportition: 0.7735849056603773\n"
     ]
    }
   ],
   "source": [
    "def count_actions(user_events, action):\n",
    "    \"\"\"Count the total number of events with type `action`\"\"\"\n",
    "    if 'Backward' in action:\n",
    "        user_events = user_events[(user_events.EventType == 'Video.Seek') & (user_events.OldTime < user_events.NewTime)]\n",
    "    elif 'Forward' in action:\n",
    "        user_events = user_events[(user_events.EventType == 'Video.Seek') & (user_events.OldTime > user_events.NewTime)]\n",
    "    else:\n",
    "        user_events = user_events[user_events.EventType == action]        \n",
    "    return len(user_events)\n",
    "\n",
    "def freq_play(user_events):\n",
    "    return count_actions(user_events,'Video.Play') / total_actions(user_events)\n",
    "\n",
    "def freq_pause(user_events):\n",
    "    return count_actions(user_events,'Video.Pause') / total_actions(user_events)\n",
    "\n",
    "def freq_seek_backward(user_events):\n",
    "    return count_actions(user_events,'Video.SeekBackward') / total_actions(user_events)\n",
    "\n",
    "def freq_seek_forward(user_events):\n",
    "    return count_actions(user_events,'Video.SeekForward') / total_actions(user_events)\n",
    "\n",
    "def freq_speed_change(user_events):\n",
    "    return count_actions(user_events,'Video.SpeedChange') / total_actions(user_events)\n",
    "\n",
    "def freq_stop(user_events):\n",
    "    return count_actions(user_events,'Video.Stop') / total_actions(user_events)\n",
    "\n",
    "total_sum = 0\n",
    "for action in [freq_play,freq_pause, freq_seek_backward, freq_seek_forward, freq_speed_change, freq_stop]:\n",
    "    freq = action(user_events)\n",
    "    total_sum += freq\n",
    "    print(action.__name__[5:], freq)\n",
    "    \n",
    "print(\"Total proportition:\", total_sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T19:27:21.840880Z",
     "start_time": "2020-11-10T19:27:21.396917Z"
    }
   },
   "source": [
    "Missing events: `Video.Transcript.Translate.EN`, `Video.Load`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Pause durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T19:59:40.959725Z",
     "start_time": "2020-11-10T19:59:40.888079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pause durations\n",
      "Average 80.45820433436532\n",
      "SG 118.52219796737265\n"
     ]
    }
   ],
   "source": [
    "def pause_duration(user_events, max_duration=600):\n",
    "    \"\"\"Compute the time interval between each pause event and the next play event`\n",
    "    Only pause durataions smaller than `max_duration` are taken into account.\"\"\"\n",
    "    \n",
    "    pause_events = user_events[user_events.EventType.isin([\"Video.Pause\", \"Video.Play\"])].copy()\n",
    "    pause_events = pause_events.sort_values(by=\"TimeStamp\")\n",
    "    pause_events['PrevEvent'] = pause_events['EventType'].shift(1)\n",
    "    pause_events['Diff'] = pause_events.TimeStamp.diff().dropna()\n",
    "    pause_events = pause_events[pause_events.PrevEvent == 'Video.Pause']\n",
    "    pause_events = pause_events[pause_events.Diff < max_duration]\n",
    "    return pause_events.Diff.values\n",
    "\n",
    "def avg_pause_duration(user_events):\n",
    "    return pause_duration(user_events).mean()\n",
    "\n",
    "def std_pause_duration(user_events):\n",
    "    return pause_duration(user_events).std()\n",
    "\n",
    "print(\"Pause durations\")\n",
    "print(\"Average\",avg_pause_duration(user_events))\n",
    "print(\"SG\",std_pause_duration(user_events))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
