{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory study on existing early warning systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Setup of the working environment *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import traditional Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:24:36.486315Z",
     "start_time": "2020-11-20T22:24:20.515516Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from datetime import datetime as dt, timedelta, date\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:24:36.662994Z",
     "start_time": "2020-11-20T22:24:36.490177Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import custom Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:24:36.675278Z",
     "start_time": "2020-11-20T22:24:36.667631Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:24:36.766743Z",
     "start_time": "2020-11-20T22:24:36.680313Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:24:42.328383Z",
     "start_time": "2020-11-20T22:24:36.771236Z"
    }
   },
   "outputs": [],
   "source": [
    "from helpers.db_connector import MySQLConnector\n",
    "from helpers.db_query import *\n",
    "\n",
    "from helpers.data_process import *\n",
    "from helpers.feature_extraction import *\n",
    "\n",
    "from extractors.akpinar_et_al import AkpinarEtAl\n",
    "from extractors.boroujeni_et_al import BoroujeniEtAl\n",
    "from extractors.chen_cui import ChenCui\n",
    "from extractors.he_et_al import HeEtAl\n",
    "from extractors.lalle_conati import LalleConati\n",
    "from extractors.lemay_doleck import LemayDoleck\n",
    "from extractors.mbouzao_et_al import MbouzaoEtAl\n",
    "from extractors.mubarak_et_al import MubarakEtAl\n",
    "from extractors.wan_et_al import WanEtAl\n",
    "\n",
    "from helpers.ml_utils import *\n",
    "\n",
    "from helpers.time import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Load the clickstream data *\n",
    "\n",
    "Since Fall 2017, the stream of the EPFL's Linear Algebra course has been taught in a flipped format. The implementation of the flipped classroom was carried out in an incremental manner, as described below:\n",
    "\n",
    "- **Year 2017-2018**: traditional manner (weeks 1-13) - flipped manner (week 14).\n",
    "- **Year 2018-2019**: traditional manner (weeks 1-4, 10-14) - flipped manner (weeks 5-9).\n",
    "- **Year 2019-2020**: traditional manner (weeks 1-4) - flipped manner (weeks 5-14)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:24:46.218522Z",
     "start_time": "2020-11-20T22:24:46.129465Z"
    }
   },
   "outputs": [],
   "source": [
    "rounds = ['Y2-2018-19', 'Y3-2019-20']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Students\n",
    "\n",
    "\n",
    "The flipped course was offered only to volunteering students. The volunteers were collectively assigned into either the experimental and the control group. A stratified random sampling based on gender and the prior background (secondary educational level) of students were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:26:03.826891Z",
     "start_time": "2020-11-20T22:24:46.229101Z"
    }
   },
   "outputs": [],
   "source": [
    "%time user_data = getUserInfo(prior_knowledge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial data of volunteers was cleaned, and some participants were removed before we analyzed the data:\n",
    "- The volunteering students who have not been graded were removed. \n",
    "- The repeating students were filtered out, where repeating students are those accessing videos in two different years. \n",
    "- The less active students, i.e., those who have provided less 60 interactions in the platform, were removed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the Y1-2017-2018 round included only one week in a flipped classroom setting, we will remove the students of that round.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:26:06.424585Z",
     "start_time": "2020-11-20T22:26:06.371873Z"
    }
   },
   "outputs": [],
   "source": [
    "user_data = user_data[user_data['Round'].isin(rounds)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the statistics on the user data are provided below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:26:06.857994Z",
     "start_time": "2020-11-20T22:26:06.801193Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"Number of students:\", len(user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:26:06.368620Z",
     "start_time": "2020-11-20T22:26:03.830848Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.displot(user_data, x='Round')\n",
    "plt.ylabel('Number of Students')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:26:06.706025Z",
     "start_time": "2020-11-20T22:26:06.426968Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.displot(user_data, x='Gender')\n",
    "plt.ylabel('Number of Students')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(user_data, x='Category')\n",
    "plt.ylabel('Number of Students')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Students' Records\n",
    "\n",
    "#### Video Clickstream Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:28:37.180870Z",
     "start_time": "2020-11-20T22:26:06.860876Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time video_data = getVideoEventsInfo(mode='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:28:39.434522Z",
     "start_time": "2020-11-20T22:28:37.184371Z"
    }
   },
   "outputs": [],
   "source": [
    "video_data = video_data[video_data['Round'].isin(rounds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:28:39.562891Z",
     "start_time": "2020-11-20T22:28:39.505581Z"
    }
   },
   "outputs": [],
   "source": [
    "\"Number of video events:\", len(video_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Clickstream Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:30:22.052434Z",
     "start_time": "2020-11-20T22:28:39.565728Z"
    }
   },
   "outputs": [],
   "source": [
    "%time problem_data = getProblemEventsInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:30:23.854203Z",
     "start_time": "2020-11-20T22:30:22.055613Z"
    }
   },
   "outputs": [],
   "source": [
    "problem_data = problem_data[problem_data['Round'].isin(rounds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:30:23.989042Z",
     "start_time": "2020-11-20T22:30:23.934426Z"
    }
   },
   "outputs": [],
   "source": [
    "\"Number of problem events:\", len(problem_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exam Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:32:32.026480Z",
     "start_time": "2020-11-20T22:30:24.000607Z"
    }
   },
   "outputs": [],
   "source": [
    "%time exam_data = getExamInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:32:33.693844Z",
     "start_time": "2020-11-20T22:32:32.032005Z"
    }
   },
   "outputs": [],
   "source": [
    "exam_data = exam_data[exam_data['Round'].isin(rounds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_data = exam_data[exam_data['AccountUserID'].isin(user_data['AccountUserID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Number of graded students:\", len(exam_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Event Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:32:34.954381Z",
     "start_time": "2020-11-20T22:32:33.759316Z"
    }
   },
   "outputs": [],
   "source": [
    "events = video_data.append(problem_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:32:36.518802Z",
     "start_time": "2020-11-20T22:32:34.957614Z"
    }
   },
   "outputs": [],
   "source": [
    "events['Year'] = events['Round'].apply(lambda x: int(x.split('-')[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Course Week Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the configuration file (e.g, start and end date) for each round of the course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T22:32:37.565867Z",
     "start_time": "2020-11-20T22:32:36.662707Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../config/linear_algebra.json') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign each video interaction to a specific week of the course, with the first week of the course round having id 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-20T22:24:29.785Z"
    }
   },
   "outputs": [],
   "source": [
    "events['Date'] = events['TimeStamp'].apply(lambda x:string2Datetime(dt.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-20T22:24:29.976Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp_events = []\n",
    "for r in rounds:\n",
    "    round_events = events[events['Round'] == r]\n",
    "    tmp_events.append(processWeek(round_events, 'Date', config[r.split('-')[-2]]['Start']))\n",
    "events = pd.concat(tmp_events).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-20T22:24:30.154Z"
    }
   },
   "outputs": [],
   "source": [
    "events['Week'] = events['Week'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we filter only the first *noCourseWeeks* course weeks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-20T22:24:30.492Z"
    }
   },
   "outputs": [],
   "source": [
    "events = events[events['Week'].isin(range(20))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Split data in training and test sets *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'random'\n",
    "task = 'binary'\n",
    "ratio = 80\n",
    "start, end, step = 2, 16, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks = np.arange(start, end, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = getTrainTestData(exam_data, mode, task, ratio / 100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Extract and scale features from clickstreams *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-20T22:24:32.990Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_labels = [\n",
    "    AkpinarEtAl(),\n",
    "    BoroujeniEtAl(),\n",
    "    ChenCui(),\n",
    "    HeEtAl(),\n",
    "    LalleConati(),\n",
    "    LemayDoleck(),\n",
    "    MbouzaoEtAl(),\n",
    "    MubarakEtAl(),\n",
    "    # WanEtAl(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we check whether the required feature sets have been already pre-computed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-20T22:24:33.238Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = '../data/feature_sets/feature_sets_' + mode + '_' + task + '_' + str(ratio) + '_' + str(start) + '-' + str(end) + '-' + str(step) + '.pkl'\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    print('Found features for this experimental setting in', filename)\n",
    "    with open(filename, 'rb') as f:\n",
    "        feature_sets = pickle.load(f)\n",
    "else:\n",
    "    feature_sets = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, for each feature set not pre-computed, the following snippet populates the corredponsing dictionary keys accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-20T22:24:34.408Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ffunc in feature_labels:\n",
    "    flabel = ffunc.getName()\n",
    "    \n",
    "    if not flabel in feature_sets:\n",
    "        feature_sets[flabel] = {}\n",
    "        \n",
    "        for wid in weeks:\n",
    "            feature_sets[flabel][wid] = {}\n",
    "            feature_sets[flabel][wid]['train'] = []\n",
    "            feature_sets[flabel][wid]['test'] = []\n",
    "            scaler = StandardScaler()\n",
    "            \n",
    "            unactiveTrain = 0\n",
    "            for uindex, uid in enumerate(x_train): \n",
    "                print('\\r', 'Set:', flabel, '- Week:', wid, '- Mode: train', '- User:', uindex + 1, len(x_train), end=' ')\n",
    "                udata = events[(events['AccountUserID'] == uid) & (events['Week'] < wid)]\n",
    "                year = int(user_data[user_data['AccountUserID'] == uid]['Round'].values[0].split('-')[-2])\n",
    "                if len(udata) > 0:\n",
    "                    feature_sets[flabel][wid]['train'].append(ffunc.getUserFeatures(udata, wid, year))\n",
    "                else:\n",
    "                    unactiveTrain += 1\n",
    "                    feature_sets[flabel][wid]['train'].append([0 for i in range(ffunc.getNbFeatures())])\n",
    "            feature_sets[flabel][wid]['train'] = scaler.fit_transform(np.array(feature_sets[flabel][wid]['train']))\n",
    "\n",
    "            print('- Unactive:', unactiveTrain, '- Active:', len(x_train) - unactiveTrain)\n",
    "            \n",
    "            unactiveTest = 0\n",
    "            for uindex, uid in enumerate(x_test): \n",
    "                print('\\r', 'Set:', flabel, '- Week:', wid, '- Mode: test', '- User:', uindex + 1, len(x_test), end=' ')\n",
    "                udata = events[(events['AccountUserID'] == uid) & (events['Week'] < wid)]\n",
    "                year = int(user_data[user_data['AccountUserID'] == uid]['Round'].values[0].split('-')[-2])\n",
    "                if len(udata) > 0:\n",
    "                    feature_sets[flabel][wid]['test'].append(ffunc.getUserFeatures(udata, wid, year))\n",
    "                else:\n",
    "                    unactiveTest += 1\n",
    "                    feature_sets[flabel][wid]['test'].append([0 for i in range(ffunc.getNbFeatures())])\n",
    "            feature_sets[flabel][wid]['test'] = scaler.transform(np.array(feature_sets[flabel][wid]['test']))\n",
    "            \n",
    "            print('- Unactive:', unactiveTest, '- Active:', len(x_test) - unactiveTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we save the feature sets computed for the current experimental setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.dirname(filename)):\n",
    "    os.makedirs(os.path.dirname(filename))\n",
    "\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(feature_sets, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Define and train the predictive models *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the prediction stage, we consider traditional shallow learning models optimized via grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-20T22:24:36.706Z"
    }
   },
   "outputs": [],
   "source": [
    "classifiers_types = {\n",
    "    'ada': AdaBoostClassifier(),\n",
    "    'dt': DecisionTreeClassifier(),\n",
    "    'gnb': GaussianNB(),\n",
    "    'lr': LogisticRegression(),\n",
    "    'mlp': MLPClassifier(),\n",
    "    'knn': KNeighborsClassifier(),\n",
    "    'rf': RandomForestClassifier(),\n",
    "    'svm': SVC()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_params = {\n",
    "    'ada': {'n_estimators': [25, 50, 100, 200], 'algorithm': ('SAMME', 'SAMME.R'), 'learning_rate': [0.1, 1]},\n",
    "    'dt': {'criterion': ('gini', 'entropy'), 'splitter': ('best', 'random'), 'max_features': ('auto', 'sqrt', 'log2')},\n",
    "    'gnb': {'var_smoothing': [1e-9, 1e-7, 1e-5, 1e-3, 1e-1]},\n",
    "    'lr': {'penalty': ('l1', 'l2', 'elasticnet', 'none'), 'tol': [1e-4, 1e-5], 'C': [1.0, 0.5], 'solver': ('newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'), 'multi_class': ('auto', 'ovr', 'multinomial')},\n",
    "    'mlp': {'activation': ('identity', 'logistic', 'tanh', 'relu'), 'solver': ('lbfgs', 'sgd', 'adam'), 'hidden_layer_sizes': [(8,), (16, 8), (32, 16, 8)]},\n",
    "    'knn': {'n_neighbors': [5, 10, 50, 100], 'weights': ('uniform', 'distance'), 'algorithm': ('auto', 'ball_tree', 'kd_tree', 'brute')},\n",
    "    'rf': {'n_estimators': [25, 50, 100, 200], 'criterion': ('gini', 'entropy'), 'max_features': ('auto', 'sqrt', 'log2')},\n",
    "    'svm': {'C': [1.0, 0.5], 'kernel': ('linear', 'poly', 'rbf', 'sigmoid'), 'gamma': ('scale', 'auto'), 'shrinking': (True, False)}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we load the trained models, in case they have been already computed under the same experimental setting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/trained_models/trained_models_' + mode + '_' + task + '_' + str(ratio) + '_' + str(start) + '-' + str(end) + '-' + str(step) + '.pkl'\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    print('Found trained_models for this experimental setting in', filename)\n",
    "    with open(filename, 'rb') as f:\n",
    "        trained_models = pickle.load(f)\n",
    "else:\n",
    "    trained_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the prediction stage is well set, we run the training procedure for each of the considered models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-20T22:24:36.797Z"
    }
   },
   "outputs": [],
   "source": [
    "for ffunc in feature_labels:\n",
    "    flabel = ffunc.getName()\n",
    "    \n",
    "    if not flabel in trained_models:\n",
    "        trained_models[flabel] = {}\n",
    "        \n",
    "        for wid in weeks:\n",
    "            trained_models[flabel][wid] = {}\n",
    "            print('Model:', flabel, '- Week:', wid, '- Algorithms:', end=' ')\n",
    "            \n",
    "            for mid in classifiers_types.keys(): \n",
    "                print(mid, end=' ')\n",
    "                trained_models[flabel][wid][mid] = GridSearchCV(classifiers_types[mid], classifiers_params[mid])\n",
    "                trained_models[flabel][wid][mid].fit(feature_sets[flabel][wid]['train'], y_train)\n",
    "            \n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We list the parameters selected by the grid search procedure, investigating whether they remain stable across weeks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ffunc in feature_labels:\n",
    "    flabel = ffunc.getName()\n",
    "    print('Feature set:', flabel)\n",
    "    for wid in weeks:\n",
    "        print('> Week:', wid)\n",
    "        for mid in classifiers_types.keys():\n",
    "            print('>> Model:', mid, '-', trained_models[flabel][wid][mid].best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we save the trained models computed for the current experimental setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.dirname(filename)):\n",
    "    os.makedirs(os.path.dirname(filename))\n",
    "\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(trained_models, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Define and compute the evaluation metrics *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-20T22:24:36.949Z"
    }
   },
   "outputs": [],
   "source": [
    "def tn(y_true, y_pred):\n",
    "    return confusion_matrix(y_true, y_pred).ravel()[0]\n",
    "\n",
    "def fp(y_true, y_pred):\n",
    "    return confusion_matrix(y_true, y_pred).ravel()[1]\n",
    "\n",
    "def fn(y_true, y_pred):\n",
    "    return confusion_matrix(y_true, y_pred).ravel()[2]\n",
    "\n",
    "def tp(y_true, y_pred):\n",
    "    return confusion_matrix(y_true, y_pred).ravel()[3]\n",
    "\n",
    "def tpr(y_true, y_pred): \n",
    "    return tp(y_true, y_pred) / (tp(y_true, y_pred) + fn(y_true, y_pred))\n",
    "\n",
    "def tnr(y_true, y_pred):\n",
    "    return tn(y_true, y_pred) / (tn(y_true, y_pred) + fp(y_true, y_pred))\n",
    "\n",
    "def fpr(y_true, y_pred): \n",
    "    return fp(y_true, y_pred) / (fp(y_true, y_pred) + tn(y_true, y_pred))\n",
    "\n",
    "def fnr(y_true, y_pred): \n",
    "    return fn(y_true, y_pred) / (tp(y_true, y_pred) + fn(y_true, y_pred))\n",
    "\n",
    "def eer(y_true, y_pred):\n",
    "    return np.mean([fnr(y_true, y_pred), fpr(y_true, y_pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditional metrics of effectiveness are considered for the prediction stage. Given that early warning systems should take particular care of the false negatives instances, the False Positive Rate will represent an essential measure of effectiveness.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-20T22:24:37.035Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluation_metrics = {\n",
    "    'Acc': accuracy_score,\n",
    "    'F1': f1_score,\n",
    "    'P': precision_score, \n",
    "    'R': recall_score,\n",
    "    'TP': tp,\n",
    "    'FN': fn,\n",
    "    'TN': tn,\n",
    "    'FP': fp,\n",
    "    'TPR': tpr,\n",
    "    'TNR': tnr,\n",
    "    'FPR': fpr, \n",
    "    'FNR': fnr,\n",
    "    'EER': eer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-20T22:24:37.120Z"
    }
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for ffunc in feature_labels:\n",
    "    flabel = ffunc.getName()\n",
    "    results[flabel] = {}\n",
    "    for wid in weeks:\n",
    "        print(flabel, wid, end='\\t')\n",
    "        results[flabel][wid] = {}\n",
    "        for mid in classifiers_types.keys(): \n",
    "            print(mid, end=' ')\n",
    "            results[flabel][wid][mid] = {}\n",
    "            clf = trained_models[flabel][wid][mid]\n",
    "            for emid, mfunc in evaluation_metrics.items():\n",
    "                results[flabel][wid][mid][emid] = mfunc(y_test, clf.predict(feature_sets[flabel][wid]['test']))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Show and discuss the results *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-20T22:24:37.288Z"
    }
   },
   "outputs": [],
   "source": [
    "lst_data = []\n",
    "lst_name = []\n",
    "for flabel in results.keys():\n",
    "    for wid in results[flabel].keys():\n",
    "        for mid in results[flabel][wid].keys():\n",
    "            lst_data.append([wid, flabel, mid] + [value for _, value in results[flabel][wid][mid].items()])  \n",
    "            lst_name = ['week', 'set', 'clf'] + [emid for emid, _ in results[flabel][wid][mid].items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-20T22:24:37.372Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(lst_data, columns = lst_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-20T22:24:37.456Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results[df_results['week'] == 2].set_index(['week', 'set', 'clf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[df_results['week'] == 14].set_index(['week', 'set', 'clf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_along_weeks(emid):\n",
    "    tnr_time = {}\n",
    "    for ffunc in feature_labels:\n",
    "        flabel = ffunc.getName()\n",
    "        tnr_time[flabel] = {}\n",
    "        for wid in weeks:\n",
    "            for mid in classifiers_types.keys(): \n",
    "                if not mid in tnr_time[flabel]:\n",
    "                    tnr_time[flabel][mid] = []\n",
    "                tnr_time[flabel][mid].append(results[flabel][wid][mid][emid])\n",
    "\n",
    "    plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    for i, ffunc in enumerate(feature_labels):\n",
    "        flabel = ffunc.getName()\n",
    "        plt.subplot(len(feature_labels) // 2, 2, i + 1)\n",
    "        plt.title(flabel)\n",
    "        colors = [plt.cm.rainbow(x) for x in np.linspace(0, 1, len(classifiers_types))]\n",
    "        for j, mid in enumerate(classifiers_types.keys()): \n",
    "            plt.plot(weeks, tnr_time[flabel][mid], 'o-', lw=1, color=colors[j], label=mid)\n",
    "        plt.ylim([0.2, 0.7])\n",
    "        plt.xlim([weeks[0], weeks[-1]])\n",
    "        plt.xlabel('Course week')\n",
    "        plt.ylabel(emid)\n",
    "        plt.grid(axis='y')\n",
    "        plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics_along_weeks('EER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
