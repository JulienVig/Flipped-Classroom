{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline algorithms for early warning systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans, silhouette_score\n",
    "from sklearn.metrics import silhouette_score, confusion_matrix\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime, timedelta, date\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calplot\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.db_connector import MySQLConnector\n",
    "from helpers.feature_extraction import *\n",
    "from helpers.data_process import *\n",
    "from helpers.db_query import *\n",
    "from helpers.time import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extractors.boroujeni_et_al import BoroujeniEtAl\n",
    "from extractors.lalle_conati import LalleConati\n",
    "from extractors.lemay_doleck import LemayDoleck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra Dataset from Courseware\n",
    "\n",
    "Since Fall 2017, the stream of the EPFL's Linear Algebra course has been taught in a flipped format. The implementation of the flipped classroom was carried out in an incremental manner, as described below:\n",
    "\n",
    "- **Year 2017-2018**: traditional manner (weeks 1-13) - flipped manner (week 14).\n",
    "- **Year 2018-2019**: traditional manner (weeks 1-4, 10-14) - flipped manner (weeks 5-9).\n",
    "- **Year 2019-2020**: traditional manner (weeks 1-4) - flipped manner (weeks 5-14)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = ['Y2-2018-19', 'Y3-2019-20']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Students\n",
    "\n",
    "\n",
    "The flipped course was offered only to volunteering students. The volunteers were collectively assigned into either the experimental and the control group. A stratified random sampling based on gender and the prior background (secondary educational level) of students were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time user_data = getUserInfo(prior_knowledge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial data of volunteers was cleaned, and some participants were removed before we analyzed the data:\n",
    "- The volunteering students who have not been graded were removed. \n",
    "- The repeating students were filtered out, where repeating students are those accessing videos in two different years. \n",
    "- The less active students, i.e., those who have provided less 60 interactions in the platform, were removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(user_data, x='Round')\n",
    "plt.ylabel('Number of Students')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the Y1-2017-2018 round included only one week in a flipped classroom setting, we decided to remove the students of that round.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = user_data[user_data['Round'].isin(rounds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(user_data, x='Gender')\n",
    "plt.ylabel('Number of Students')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how our user table looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Hence, we will work with \" + str(len(user_data)) + \" students.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Students' Records\n",
    "\n",
    "#### Video Clickstream Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time video_data = getVideoEventsInfo().rename(columns={'VideoID': 'ElementID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_data = video_data[video_data['Round'].isin(rounds)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how our video event table looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Hence, we will work with \" + str(len(video_data)) + \" video interactions.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Clickstream Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time problem_data = getProblemEventsInfo().rename(columns={'ProblemID': 'ElementID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_data = problem_data[problem_data['Round'].isin(rounds)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how our problem event table looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Hence, we will work with \" + str(len(problem_data)) + \" problem interactions.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exam Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time exam_data = getExamInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter the exam records of students who have not participated into the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_data = exam_data[exam_data['Round'].isin(rounds)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how our exam data looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Event Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = video_data[['AccountUserID', 'ElementID', 'TimeStamp', 'EventType', 'Round']]\n",
    "d2 = problem_data[['AccountUserID', 'ElementID', 'TimeStamp', 'EventType', 'Round']]\n",
    "\n",
    "events = d1.append(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how our join event table looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noCourseWeeks = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the configuration file (e.g, start and end date) for each round of the course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config/linear_algebra.json') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[rounds[0].split('-')[-2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign each video interaction to a specific week of the course, with the first week of the course round having id 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events['Date'] = events['TimeStamp'].apply(lambda x:string2Datetime(dt.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_events = []\n",
    "for r in rounds:\n",
    "    round_events = events[events['Round'] == r]\n",
    "    tmp_events.append(processWeek(round_events, 'Date', config[r.split('-')[-2]]['Start']))\n",
    "events = pd.concat(tmp_events).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events['Week'] = events['Week'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we filter only the 14 course weeks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = events[events['Week'].isin(range(noCourseWeeks))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how our event table looks like, after week addition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.sort_values(by='Week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'random' # per-year\n",
    "train_ratio = 0.90\n",
    "task = 'binary' # multi-class, regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = exam_data['AccountUserID'].values\n",
    "\n",
    "if task == 'binary':\n",
    "    print('Binarizing the student grades')\n",
    "    y = [(1 if grade >= 4.0 else 0) for grade in exam_data['Grade']]\n",
    "    print('Pass', y.count(1), 'Fail', y.count(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'random':\n",
    "    print('Spitting the whole student population randomly')\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=1 - train_ratio)\n",
    "    print('Train Pass', y_train.count(1), 'Test Pass', y_test.count(1), 'Train Fail', y_train.count(0), 'Test Fail', y_test.count(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_thresholds = np.arange(4, 24, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_labels = {\n",
    "    BoroujeniEtAl(),\n",
    "    LalleConati(),\n",
    "    LemayDoleck(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = {} \n",
    "for ffunc in feature_labels:\n",
    "    flabel = ffunc.getName()\n",
    "    feature_sets[flabel] = {}\n",
    "    for wid in week_thresholds:\n",
    "        feature_sets[flabel][wid] = {}\n",
    "        feature_sets[flabel][wid]['train'] = []\n",
    "        feature_sets[flabel][wid]['test'] = []\n",
    "        scaler = StandardScaler()\n",
    "        for uindex, uid in enumerate(x_train): \n",
    "            print('\\r', 'Set:', flabel, '\\tWeek:', wid, '\\tMode: train', '\\tProgress:', uindex + 1, len(x_train), end='')\n",
    "            udata = events[(events['AccountUserID'] == uid) & (events['Week'] < wid)]\n",
    "            feature_sets[flabel][wid]['train'].append(ffunc.getUserFeatures(udata))\n",
    "        feature_sets[flabel][wid]['train'] = scaler.fit_transform(np.array(feature_sets[flabel][wid]['train']))\n",
    "        print()\n",
    "        for uindex, uid in enumerate(x_test): \n",
    "            print('\\r', 'Set:', flabel, '\\tWeek:', wid, '\\tMode: test', '\\tProgress:', uindex + 1, len(x_test), end='')\n",
    "            udata = events[(events['AccountUserID'] == uid) & (events['Week'] < wid)]\n",
    "            feature_sets[flabel][wid]['test'].append(ffunc.getUserFeatures(udata))\n",
    "        feature_sets[flabel][wid]['test'] = scaler.fit_transform(np.array(feature_sets[flabel][wid]['test']))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_types = {\n",
    "    'ada': AdaBoostClassifier(),\n",
    "    'dt': DecisionTreeClassifier(max_depth=5),\n",
    "    'gnb': GaussianNB(),\n",
    "    'lr': LogisticRegression(),\n",
    "    'mlp': MLPClassifier(alpha=1, max_iter=1000),\n",
    "    'knn': KNeighborsClassifier(3),\n",
    "    'rf': RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    'svm': SVC(gamma=2, C=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models = {}\n",
    "for ffunc in feature_labels:\n",
    "    flabel = ffunc.getName()\n",
    "    trained_models[flabel] = {}\n",
    "    for wid in week_thresholds:\n",
    "        trained_models[flabel][wid] = {}\n",
    "        print(flabel, wid, end='\\t')\n",
    "        for mid, clf in classifiers_types.items(): \n",
    "            print(mid, end=' ')\n",
    "            trained_models[flabel][wid][mid] = clf.fit(feature_sets[flabel][wid]['train'], y_train)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tn(y_true, y_pred):\n",
    "    return confusion_matrix(y_true, y_pred).ravel()[0]\n",
    "\n",
    "def fp(y_true, y_pred):\n",
    "    return confusion_matrix(y_true, y_pred).ravel()[1]\n",
    "\n",
    "def fn(y_true, y_pred):\n",
    "    return confusion_matrix(y_true, y_pred).ravel()[2]\n",
    "\n",
    "def tp(y_true, y_pred):\n",
    "    return confusion_matrix(y_true, y_pred).ravel()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_metrics = {\n",
    "    'acc': accuracy_score,\n",
    "    'f1': f1_score,\n",
    "    'p': precision_score, \n",
    "    'r': recall_score,\n",
    "    'tp': tp,\n",
    "    'tn': tn,\n",
    "    'fp': fp,\n",
    "    'fn': fn\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for ffunc in feature_labels:\n",
    "    flabel = ffunc.getName()\n",
    "    results[flabel] = {}\n",
    "    for wid in week_thresholds:\n",
    "        print(flabel, wid, end='\\t')\n",
    "        results[flabel][wid] = {}\n",
    "        for mid, clf in classifiers_types.items(): \n",
    "            print(mid, end=' ')\n",
    "            results[flabel][wid][mid] = {}\n",
    "            for emid, mfunc in evaluation_metrics.items():\n",
    "                results[flabel][wid][mid][emid] = mfunc(y_test, clf.predict(feature_sets[flabel][wid]['test']))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_data = []\n",
    "lst_name = []\n",
    "for flabel in results.keys():\n",
    "    for wid in results[flabel].keys():\n",
    "        for mid in results[flabel][wid].keys():\n",
    "            lst_data.append([wid, flabel, mid] + [value for _, value in results[flabel][wid][mid].items()])  \n",
    "            lst_name = ['week', 'set', 'clf'] + [emid for emid, _ in results[flabel][wid][mid].items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(lst_data, columns = lst_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[df_results['week'] == 8].set_index(['week', 'set', 'clf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[df_results['week'] == 16].set_index(['week', 'set', 'clf'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
